library(rgl)
# Generate half-moon dataset
JG_generateHalfMoon <- function(dataPoins, sd){
# First half-moon
x1 <- seq(0, pi, pi/(dataPoins-1))
y1 <- sin(x1) + rnorm(dataPoins, mean = 0, sd = sd)
z1 <- runif(dataPoins) * 10
labels1 <- rep(1,dataPoins)
# Second half-moon
x2 <- seq(pi, 2*pi, pi/(dataPoins-1))
y2 <- sin(x2) + rnorm(dataPoins, mean = 0, sd = sd)
x2 <- x2 - pi/2
z2 <- runif(dataPoins) * 10
labels2 <- rep(2,dataPoins)
x <- c(x1,x2)
y <- c(y1,y2)
z <- c(z1,z2)
labels <- c(labels1,labels2)
dataset <- cbind(x,y,z,labels)
return (dataset)
}
dataPoins <- 500
sd <- 0.15
dataset <- JG_generateHalfMoon(dataPoins, sd)
#Plot 2D
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
# Plot 3D
plot3d(dataset[,1], dataset[,2], dataset[,3],col= scales::alpha(dataset[,4]+1,0.3), type="p")
dataPoins <- 500
sd <- 0.2
dataset <- JG_generateHalfMoon(dataPoins, sd)
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
# Generate half-moon dataset
JG_generateHalfMoon <- function(dataPoins, sd){
# First half-moon
x1 <- seq(0, pi, pi/(dataPoins-1))
y1 <- sin(2*x1) + rnorm(dataPoins, mean = 0, sd = sd)
z1 <- runif(dataPoins) * 10
labels1 <- rep(1,dataPoins)
# Second half-moon
x2 <- seq(pi, 2*pi, pi/(dataPoins-1))
y2 <- sin(2*x2) + rnorm(dataPoins, mean = 0, sd = sd)
x2 <- x2 - pi/2
z2 <- runif(dataPoins) * 10
labels2 <- rep(2,dataPoins)
x <- c(x1,x2)
y <- c(y1,y2)
z <- c(z1,z2)
labels <- c(labels1,labels2)
dataset <- cbind(x,y,z,labels)
return (dataset)
}
dataPoins <- 500
sd <- 0.2
dataset <- JG_generateHalfMoon(dataPoins, sd)
#Plot 2D
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
# Generate half-moon dataset
JG_generateHalfMoon <- function(dataPoins, sd){
# First half-moon
x1 <- seq(0, pi, pi/(dataPoins-1))
y1 <- 2*sin(x1) + rnorm(dataPoins, mean = 0, sd = sd)
z1 <- runif(dataPoins) * 10
labels1 <- rep(1,dataPoins)
# Second half-moon
x2 <- seq(pi, 2*pi, pi/(dataPoins-1))
y2 <- 2*sin(x2) + rnorm(dataPoins, mean = 0, sd = sd)
x2 <- x2 - pi/2
z2 <- runif(dataPoins) * 10
labels2 <- rep(2,dataPoins)
x <- c(x1,x2)
y <- c(y1,y2)
z <- c(z1,z2)
labels <- c(labels1,labels2)
dataset <- cbind(x,y,z,labels)
return (dataset)
}
dataPoins <- 500
sd <- 0.2
dataset <- JG_generateHalfMoon(dataPoins, sd)
#Plot 2D
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
sd <- 0.4
dataset <- JG_generateHalfMoon(dataPoins, sd)
dataPoins <- 500
sd <- 1
dataset <- JG_generateHalfMoon(dataPoins, sd)
# Generate half-moon dataset
JG_generateHalfMoon <- function(dataPoins, sd){
# First half-moon
x1 <- seq(0, pi, pi/(dataPoins-1))
y1 <- 2*sin(x1) + rnorm(dataPoins, mean = 0, sd = sd)
z1 <- runif(dataPoins) * 10
labels1 <- rep(1,dataPoins)
# Second half-moon
x2 <- seq(pi, 2*pi, pi/(dataPoins-1))
y2 <- 2*sin(x2) + rnorm(dataPoins, mean = 0, sd = sd)
x2 <- x2 - pi/2
z2 <- runif(dataPoins) * 10
labels2 <- rep(2,dataPoins)
x <- c(x1,x2)
y <- c(y1,y2)
z <- c(z1,z2)
labels <- c(labels1,labels2)
dataset <- cbind(x,y,z,labels)
return (dataset)
}
dataPoins <- 500
sd <- 0.4
dataset <- JG_generateHalfMoon(dataPoins, sd)
sd <- 2
dataset <- JG_generateHalfMoon(dataPoins, sd)
# Generate half-moon dataset
JG_generateHalfMoon <- function(dataPoins, sd){
# First half-moon
x1 <- seq(0, pi, pi/(dataPoins-1))
y1 <- sin(x1) + rnorm(dataPoins, mean = 0, sd = sd)
z1 <- runif(dataPoins) * 10
labels1 <- rep(1,dataPoins)
# Second half-moon
x2 <- seq(pi, 2*pi, pi/(dataPoins-1))
y2 <- sin(x2) + rnorm(dataPoins, mean = 0, sd = sd)
x2 <- x2 - pi/2
z2 <- runif(dataPoins) * 10
labels2 <- rep(2,dataPoins)
x <- c(x1,x2)
y <- c(y1,y2)
z <- c(z1,z2)
labels <- c(labels1,labels2)
dataset <- cbind(x,y,z,labels)
return (dataset)
}
dataPoins <- 500
sd <- 0.2
dataset <- JG_generateHalfMoon(dataPoins, sd)
#Plot 2D
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
dataPoins <- 500
sd <- 0.4
dataset <- JG_generateHalfMoon(dataPoins, sd)
# Generate half-moon dataset
JG_generateHalfMoon <- function(dataPoins, sd){
# First half-moon
x1 <- seq(0, pi, pi/(dataPoins-1))
y1 <- 2*sin(x1) + rnorm(dataPoins, mean = 0, sd = sd)
z1 <- runif(dataPoins) * 10
labels1 <- rep(1,dataPoins)
# Second half-moon
x2 <- seq(pi, 2*pi, pi/(dataPoins-1))
y2 <- 2*sin(x2) + rnorm(dataPoins, mean = 0, sd = sd)
x2 <- x2 - pi/2
z2 <- runif(dataPoins) * 10
labels2 <- rep(2,dataPoins)
x <- c(x1,x2)
y <- c(y1,y2)
z <- c(z1,z2)
labels <- c(labels1,labels2)
dataset <- cbind(x,y,z,labels)
return (dataset)
}
dataPoins <- 500
sd <- 0.4
dataset <- JG_generateHalfMoon(dataPoins, sd)
#Plot 2D
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
sd <- 0.5
dataset <- JG_generateHalfMoon(dataPoins, sd)
#Plot 2D
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
# Generate half-moon dataset
JG_generateHalfMoon <- function(dataPoins, sd){
# First half-moon
x1 <- seq(0, pi, pi/(dataPoins-1))
y1 <- 4*sin(x1) + rnorm(dataPoins, mean = 0, sd = sd)
z1 <- runif(dataPoins) * 10
labels1 <- rep(1,dataPoins)
# Second half-moon
x2 <- seq(pi, 2*pi, pi/(dataPoins-1))
y2 <- 4*sin(x2) + rnorm(dataPoins, mean = 0, sd = sd)
x2 <- x2 - pi/2
z2 <- runif(dataPoins) * 10
labels2 <- rep(2,dataPoins)
x <- c(x1,x2)
y <- c(y1,y2)
z <- c(z1,z2)
labels <- c(labels1,labels2)
dataset <- cbind(x,y,z,labels)
return (dataset)
}
dataPoins <- 500
sd <- 0.4
dataset <- JG_generateHalfMoon(dataPoins, sd)
#Plot 2D
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
dataPoins <- 500
sd <- 0.6
dataset <- JG_generateHalfMoon(dataPoins, sd)
#Plot 2D
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
dataPoins <- 500
sd <- 0.8
dataset <- JG_generateHalfMoon(dataPoins, sd)
#Plot 2D
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
dataPoins <- 500
sd <- 0.6
dataset <- JG_generateHalfMoon(dataPoins, sd)
#Plot 2D
plot(dataset[,1],dataset[,2], col= scales::alpha(dataset[,4]+1,0.3), pch=20)
# Plot 3D
plot3d(dataset[,1], dataset[,2], dataset[,3],col= scales::alpha(dataset[,4]+1,0.3), type="p")
z <- cos(dataset[,2])
plot3d(dataset[,1], dataset[,2], z,col= scales::alpha(dataset[,4]+1,0.3), type="p")
z <- sin(dataset[,2])
plot3d(dataset[,1], dataset[,2], z,col= scales::alpha(dataset[,4]+1,0.3), type="p")
z <- cos(dataset[,2])
plot3d(dataset[,1], dataset[,2], z,col= scales::alpha(dataset[,4]+1,0.3), type="p")
rm(list=ls())
load(file="Data/2gaussiandata.RData")
load(file="D~/OneDrive - Universidad Politécnica de Madrid/Documentos/MSc DM/2ºDM/Data mining/HA/ha1-data-mining.-javier-galindos/Data/2gaussiandata.RData")
load(file="~/OneDrive - Universidad Politécnica de Madrid/Documentos/MSc DM/2ºDM/Data mining/HA/ha1-data-mining.-javier-galindos/Data/2gaussiandata.RData")
JG_fisherScore <- function(feature, labels){
#n_classes <- length(unique(labels))
# Mean of each class
mu_j <- aggregate(feature, list(labels), mean)
# Standard deviation of each class
sigma_j <- aggregate(feature, list(labels), sd)
# Global mean
mu <- mean(feature)
# Fraction of points belonging to the same class
p_j <- table(labels) / length(labels)
# Compute Fisher score
numerator <- p_j * ((mu_j$x - mu)^2)
denominator <- p_j * sigma_j$x
FisherScore <- sum(numerator) / sum(denominator)
return (FisherScore)
}
FS <- JG_fisherScore(x[,2],labels)
FS <- JG_fisherScore(x[,2],x[,3])
FS <- JG_fisherScore(x[,1],x[,3])
# Exercise 2: Classification
# Javier Galindos
rm(list=ls())
library("rstudioapi")
library("caret")
library("dplyr") # Manipulating variables
library("MLmetrics") # Goodness parameters
# Set working directory
setwd(dirname(getActiveDocumentContext()$path))
# Exercise 2: Classification
# Javier Galindos
rm(list=ls())
library("rstudioapi")
#library("caret")
library("dplyr") # Manipulating variables
library("MLmetrics") # Goodness parameters
# Set working directory
setwd(dirname(getActiveDocumentContext()$path))
getwd()
# loading the data from file
load(file="Data/JGdata.RData")
#data plotting - visualization
plot(x[,1],x[,2], col=scales::alpha(labels+1,0.3), pch=20, main ='JG Dataset')
# Load distance function
source("JG_distance.R")
# Distance metric
distFun= "Euclidean"
JG_knn<- function(testSet, trainSet, trainLabels, k){
# Get the distance to k nearest neighbor of every point (knn_distance)
# and index of k-neighbors (neighbors)
knn_distance <- matrix(,nrow = nrow(testSet)) # Create the array for the distance
neighbors <- matrix(,nrow = nrow(testSet), ncol = k) # Array for index of neighbors
for (i in seq(along=1:nrow(testSet))){
temp_dist <- matrix(,nrow = nrow(trainSet))
# Compute distance to each point
for (j in seq(along=1:nrow(trainSet))){
temp_dist[j] = JG_dist(testSet[i,], trainSet[j,], distFun)
}
# Take the k lowest distance
temp_dist <- sort(temp_dist,index.return=TRUE)
knn_distance[i] <- temp_dist$x[k]
# Save the index of the k neighbors
neighbors[i,] <- temp_dist$ix[1:k]
}
# Check the most frequent value of the neighbors
testPredict <- matrix(,nrow = nrow(testSet))
for (i in seq(along=1:nrow(testSet))){
# Index of neighbors
idx_i <- neighbors[i,]
# Labels of these neighbors
labels_i <- trainLabels[idx_i]
# Get the most frequent neighbor
unique_i <- unique(na.omit(labels_i))
testPredict[i] <- unique_i[which.max(tabulate(match(labels_i, unique_i)))]
}
return (testPredict)
}
JG_decisionTree<- function(testSet, trainSet, trainLabels){
# Pre-proccess as data frame
train <- cbind(trainSet,trainLabels)
train <- as.data.frame(train)
test <- as.data.frame(testSet)
classColumNum <- ncol(train)
# Initialize ID
idx <<- 3
# Gini index
gini_index <- function(y){
if(length(y) == 0) return(0)
p <- table(y)/length(y)
return (1-sum(p^2))
}
# Generate unique number to give an ID to each node of Decision Tree
idGen <- function(){
idx <<- idx + 4
return (idx)
}
# Find the best split
best_split <- function(train){
classColumNum <- ncol(train)
summaryColumnGini <- matrix(data= NA,ncol = 3,byrow = T)
# Loop over independent variables
for(col in 1:(ncol(train)-1)){
# Compute mid-point vector between contiguous points
colValue <- train[,col]
colValue <- sort(colValue)
colValue <- unique(colValue)
meanPointVector <- rep(NA,length(colValue))
for(i in 1:length(colValue)){
# Add previous value if it is NA
if(is.na(colValue[i+1]) == T){
colValue[i+1] <- colValue[i]
}
meanPoint <- (colValue[i]+ colValue[i+1])/2
meanPointVector[i] <- meanPoint
}
# Get rid off NA
meanPointVector <- meanPointVector[!is.na(meanPointVector)]
summaryGini <- matrix(data= NA,ncol = 2,byrow = T)
# Loop over every raw != NA
for(i in 1:length(meanPointVector)){
totalRecords <- nrow(train)
splitLeft <- train[train[,col] < meanPointVector[i],]
splitRight <- train[train[,col] >= meanPointVector[i],]
splitLeft.totalRecords <- nrow(splitLeft)
splitRight.totalRecords <- nrow(splitRight)
# Get Gini information
if(splitLeft.totalRecords >0){
splitLeft.gini <- gini_index(splitLeft[,classColumNum])
}else{
splitLeft.gini <- 0
}
if(splitRight.totalRecords >0){
splitRight.gini <- gini_index(splitRight[,classColumNum])
}else{
splitRight.gini <- 0
}
# Weighted mean of Gini Index
gini_split <- as.double(splitLeft.gini * (splitLeft.totalRecords/totalRecords)) + as.double(splitRight.gini * (splitRight.totalRecords/totalRecords))
# Add a little constant whether is 0
if(splitLeft.gini == 0 | splitRight.gini == 0){
gini_split <- gini_split + 0.01
}
summaryGini <- rbind(summaryGini,c(meanPointVector[i],gini_split))
}
# Get the splitting that yields to minimum Gini index
summaryGini <- summaryGini[which.min(summaryGini[,2]),]
splitValue <- summaryGini[1]
giniValue <- summaryGini[2]
summaryColumnGini <- rbind(summaryColumnGini,c(col,splitValue,giniValue))
}
# Get summary of each variable (column)
summaryColumnGini <- summaryColumnGini[which.min(summaryColumnGini[,3]),]
colNum <- summaryColumnGini[1]
splitValue <- summaryColumnGini[2]
giniValue <- summaryColumnGini[3]
return(c(colNum,splitValue,giniValue))
}
# Global variables:
sequ <<- 0
nodeOwnNum <<- 0
child0 <<- 1
child1 <<- 2
parent <<- 0
summary_train_model <<- data.frame(NodeNum = NA, SplitColumn= NA, SplitValue=NA, ClassLabel= NA,NodeType = NA,Parent=NA,Child0= NA,Child1= NA,stringsAsFactors = F)
growTree <- function(dataset,nodeOwnNum,sequ,parent,child0,child1){
sequ <- sequ + 2
dataset.classes <- nlevels(factor(dataset[,classColumNum]))
# Check whether it is leaf(LN) or internal node (IN)
# It is Leaf Node if there is only class in the subset
if(dataset.classes == 1){ # Leaf node (LN)
summary_train_model <<- rbind(summary_train_model,list(nodeOwnNum,NA,NA,dataset[1,classColumNum],"LN",parent,NA,NA))
}
else{ # Internal node (IN)
dataset.splitSummary <- best_split(dataset)
dataset.colNum <- dataset.splitSummary[1]
dataset.splitValue <- dataset.splitSummary[2]
summary_train_model <<- rbind(summary_train_model,list(nodeOwnNum,dataset.colNum,dataset.splitValue,NA,"IN",parent,child0,child1))
# Split dataset with condition dataset[,dataset.colNum] < dataset.splitValue
splitLeft <- dataset[dataset[,dataset.colNum] < dataset.splitValue,]
splitRight <- dataset[dataset[,dataset.colNum] >= dataset.splitValue,]
# Grow tree recursively
if(!(nrow(splitLeft) == 0)){
growTree(splitLeft,child0,sequ,nodeOwnNum,idGen(),idGen())
}
if(!(nrow(splitRight) == 0)){
growTree(splitRight,child1,sequ,nodeOwnNum,idGen(),idGen())
}
}
}
growTree(train,nodeOwnNum,sequ,parent,child0,child1)
summary_train_model <- summary_train_model[-1,]
# Function to predict
predict <- function(record,parent,nodenum){
# Select the node -> nodenum
node <- summary_train_model %>% filter(NodeNum == nodenum) %>%  select(NodeNum,SplitColumn,SplitValue,NodeType,ClassLabel,Parent,Child0,Child1)
# Check whether it is leaf(LN) or internal node (IN)
if(node$NodeType == "LN"){
# Return class if it is Leaf Node
return(node$ClassLabel)
}
else{
# Go through the tree if it is Interal Node
split.column <- node$SplitColumn
split.value <- node$SplitValue
childNode <- NA
if(record[,split.column] < split.value){
childNode <- node$Child0
}else{
childNode <- node$Child1
}
parent <- node$Parent
# Predict recursively
predict(record,parent,childNode)
}
}
df.predictedValue <<- data.frame(predictedValue = NA)
for(n in 1:nrow(test)){
pred.ClassLabel <-  predict(test[n,],0,0)
df.predictedValue <- rbind(df.predictedValue,pred.ClassLabel)
}
pred <- df.predictedValue[-1,]
return(pred)
}
# Goodness parameters
JG_accuracy <- function(yPred, yTrue){
conf <- table(yPred, yTrue)
accuracy <- sum(diag(conf))/sum(conf)
}
JG_precision <- function(yPred, yTrue){
conf <- table(yPred, yTrue)
prec <- matrix(,nrow = nrow(conf))
for (i in seq(1:nrow(conf))){
prec[i] <- conf[i,i] / sum (conf[i,])
}
return (prec)
}
JG_recall <- function(yPred, yTrue){
conf <- table(yPred, yTrue)
recall <- matrix(,nrow = nrow(conf))
for (i in seq(1:nrow(conf))){
recall[i] <- conf[i,i] / sum (conf[,i])
}
return (recall)
}
JG_F1score <- function(yPred, yTrue){
conf <- table(yPred, yTrue)
prec  <- matrix(,nrow = nrow(conf))
recall <- matrix(,nrow = nrow(conf))
F1score <- matrix(,nrow = nrow(conf))
for (i in seq(1:nrow(conf))){
prec[i] <- conf[i,i] / sum (conf[i,])
recall[i] <- conf[i,i] / sum (conf[,i])
F1score[i] <- 2 * prec[i] * recall[i] / (prec[i] + recall[i])
}
return (F1score)
}
# Data preparation. Split datatset
#split the data in proportion 70/30 for training and test purposes.
training_percentage = 70
sample_size <- floor((training_percentage/100) * nrow(x))
train_ind <- sample(seq_len(nrow(x)), size = sample_size)
trainSet <- x[train_ind, ]
trainLabels <- labels[train_ind]
testSet <- x[-train_ind, ]
testLabels <- labels[-train_ind]
# KNN
# Determined using Leave-one-out cross validation
k <- 5
# Prediction on train set
trainPredict_knn <- JG_knn(trainSet, trainSet, trainLabels, k)
# Decision Tree
testPredict_DT <- JG_decisionTree(testSet, trainSet, trainLabels)
# Plotting
symbols <- 1*(testLabels==testPredict_DT) # Misclassification
symbols[symbols ==1] <- 20
symbols[symbols ==0] <- 4
colors <- testPredict_DT + 1
colors[testLabels!=testPredict_DT] <- 9
plot(testSet[,1],testSet[,2], col=scales::alpha(colors,0.5), pch=symbols, main ='Decision Tree Test set prediction')
# Performance
test_conf_knn <- table(testPredict_knn, testLabels)
# KNN
# Determined using Leave-one-out cross validation
k <- 5
# Prediction on test set
testPredict_knn <- JG_knn(testSet, trainSet, trainLabels, k)
# Performance
test_conf_knn <- table(testPredict_knn, testLabels)
test_conf_knn
# Performance
test_conf_DT <- table(testPredict_DT, testLabels)
test_conf_DT
